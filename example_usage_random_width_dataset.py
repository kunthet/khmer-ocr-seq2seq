#!/usr/bin/env python3
"""
Example usage of RandomWidthDataset for improving short text performance.
This script demonstrates how to integrate the dataset into your training pipeline.
"""

import sys
sys.path.append('src')

import torch
from torch.utils.data import DataLoader
from src.data.random_width_dataset import RandomWidthDataset

def example_basic_usage():
    """Basic usage example with your existing dataset."""
    print("üîß Basic RandomWidthDataset Usage Example")
    print("=" * 50)
    
    # Example: Replace this with your actual OnTheFlyDataset
    from test_random_width_dataset import MockBaseDataset, MockConfigManager
    
    # Create your base dataset and config
    base_dataset = MockBaseDataset(1000)  # Your OnTheFlyDataset here
    config_manager = MockConfigManager()  # Your actual config manager
    
    # Create RandomWidthDataset with strong bias toward short texts
    short_text_dataset = RandomWidthDataset(
        base_dataset=base_dataset,
        min_length=1,
        max_length=150,
        alpha=0.05,  # Strong bias toward short texts (lower = more bias)
        config_manager=config_manager
    )
    
    print(f"‚úÖ Created dataset with {len(short_text_dataset)} samples")
    
    # Check the distribution
    stats = short_text_dataset.get_length_statistics()
    total_texts = sum(stats.values())
    short_texts = sum(count for length, count in stats.items() if length <= 10)
    
    print(f"‚úÖ Generated {total_texts} text variations")
    print(f"‚úÖ Short texts (‚â§10 chars): {short_texts} ({short_texts/total_texts:.1%})")
    
    # Sample some data
    sample = short_text_dataset[0]
    print(f"‚úÖ Sample text: '{sample['text'][:50]}...' (length: {sample['actual_length']})")
    
    return short_text_dataset

def example_dataloader_integration():
    """Example of using RandomWidthDataset with PyTorch DataLoader."""
    print("\nüîß DataLoader Integration Example")
    print("=" * 50)
    
    # Create dataset
    from test_random_width_dataset import MockBaseDataset, MockConfigManager
    base_dataset = MockBaseDataset(500)
    config_manager = MockConfigManager()
    
    short_text_dataset = RandomWidthDataset(
        base_dataset=base_dataset,
        min_length=1,
        max_length=100,
        alpha=0.08,  # Moderate bias toward short texts
        config_manager=config_manager
    )
    
    # Custom collate function for batching
    def collate_fn(batch):
        # Handle variable-width images by padding to max width
        images = [item['image'] for item in batch]
        max_width = max(img.shape[-1] for img in images)
        
        padded_images = []
        for img in images:
            if img.shape[-1] < max_width:
                # Pad with zeros on the right
                padding = torch.zeros(img.shape[0], img.shape[1], max_width - img.shape[-1])
                padded_img = torch.cat([img, padding], dim=-1)
            else:
                padded_img = img
            padded_images.append(padded_img)
        
        images_tensor = torch.stack(padded_images)
        
        # Pad target sequences to the same length
        targets = [item['targets'] for item in batch]
        max_len = max(len(target) for target in targets)
        
        padded_targets = []
        for target in targets:
            padded = torch.cat([
                target,
                torch.zeros(max_len - len(target), dtype=torch.long)
            ])
            padded_targets.append(padded)
        
        target_tensor = torch.stack(padded_targets)
        
        # Additional info
        texts = [item['text'] for item in batch]
        actual_lengths = [item['actual_length'] for item in batch]
        
        return {
            'images': images_tensor,
            'targets': target_tensor,
            'texts': texts,
            'lengths': actual_lengths
        }
    
    # Create DataLoader
    dataloader = DataLoader(
        short_text_dataset,
        batch_size=32,
        shuffle=True,
        collate_fn=collate_fn,
        num_workers=0  # Set to > 0 for multiprocessing
    )
    
    # Test a batch
    batch = next(iter(dataloader))
    print(f"‚úÖ Batch shape: {batch['images'].shape}")
    print(f"‚úÖ Target shape: {batch['targets'].shape}")
    print(f"‚úÖ Batch length range: {min(batch['lengths'])} - {max(batch['lengths'])}")
    
    # Show some examples from the batch
    for i in range(min(3, len(batch['texts']))):
        text = batch['texts'][i]
        length = batch['lengths'][i]
        print(f"   Example {i+1}: '{text[:30]}...' (len: {length})")
    
    return dataloader

def example_curriculum_learning():
    """Example of using RandomWidthDataset for curriculum learning."""
    print("\nüîß Curriculum Learning Example")
    print("=" * 50)
    
    from test_random_width_dataset import MockBaseDataset, MockConfigManager
    base_dataset = MockBaseDataset(1000)
    config_manager = MockConfigManager()
    
    # Create datasets with different alpha values for curriculum stages
    stages = [
        {"name": "Stage 1: Very Short Texts", "alpha": 0.15, "epochs": 5},
        {"name": "Stage 2: Short to Medium", "alpha": 0.08, "epochs": 10},
        {"name": "Stage 3: Balanced", "alpha": 0.05, "epochs": 15},
    ]
    
    for stage in stages:
        print(f"\nüìö {stage['name']}")
        
        dataset = RandomWidthDataset(
            base_dataset=base_dataset,
            min_length=1,
            max_length=150,
            alpha=stage['alpha'],
            config_manager=config_manager
        )
        
        # Analyze distribution
        samples = [dataset[i] for i in range(100)]
        lengths = [s['actual_length'] for s in samples]
        
        short_ratio = sum(1 for l in lengths if l <= 10) / len(lengths)
        medium_ratio = sum(1 for l in lengths if 11 <= l <= 30) / len(lengths)
        long_ratio = sum(1 for l in lengths if l > 30) / len(lengths)
        
        print(f"   Short (‚â§10): {short_ratio:.1%}")
        print(f"   Medium (11-30): {medium_ratio:.1%}")
        print(f"   Long (>30): {long_ratio:.1%}")
        print(f"   Recommended epochs: {stage['epochs']}")

def example_comparison_with_original():
    """Compare RandomWidthDataset with original dataset length distribution."""
    print("\nüîß Distribution Comparison Example")
    print("=" * 50)
    
    from test_random_width_dataset import MockBaseDataset, MockConfigManager
    base_dataset = MockBaseDataset(1000)
    config_manager = MockConfigManager()
    
    # Original dataset lengths
    original_lengths = [len(text) for text in base_dataset.text_lines]
    
    # RandomWidthDataset samples
    short_text_dataset = RandomWidthDataset(
        base_dataset=base_dataset,
        min_length=1,
        max_length=150,
        alpha=0.05,
        config_manager=config_manager
    )
    
    random_samples = [short_text_dataset[i] for i in range(1000)]
    random_lengths = [s['actual_length'] for s in random_samples]
    
    # Compare distributions
    def analyze_distribution(lengths, name):
        short = sum(1 for l in lengths if l <= 10) / len(lengths)
        medium = sum(1 for l in lengths if 11 <= l <= 50) / len(lengths)
        long = sum(1 for l in lengths if l > 50) / len(lengths)
        avg_length = sum(lengths) / len(lengths)
        
        print(f"\n{name}:")
        print(f"   Short (‚â§10): {short:.1%}")
        print(f"   Medium (11-50): {medium:.1%}")
        print(f"   Long (>50): {long:.1%}")
        print(f"   Average length: {avg_length:.1f}")
        return short, medium, long
    
    original_dist = analyze_distribution(original_lengths, "üìä Original Dataset")
    random_dist = analyze_distribution(random_lengths, "üìä RandomWidthDataset")
    
    improvement = random_dist[0] - original_dist[0]
    print(f"\n‚ú® Improvement in short text representation: +{improvement:.1%}")

def main():
    """Run all examples."""
    print("üöÄ RandomWidthDataset Usage Examples")
    print("=" * 60)
    
    try:
        # Run examples
        dataset = example_basic_usage()
        dataloader = example_dataloader_integration()
        example_curriculum_learning()
        example_comparison_with_original()
        
        print("\n" + "=" * 60)
        print("‚úÖ All examples completed successfully!")
        print("\nüìã Key Takeaways:")
        print("‚Ä¢ Use alpha=0.05-0.15 for strong bias toward short texts")
        print("‚Ä¢ Implement curriculum learning with different alpha stages")
        print("‚Ä¢ Use custom collate_fn for variable-length sequences")
        print("‚Ä¢ Monitor length distribution during training")
        print("‚Ä¢ Expected 3-5x improvement in short text representation")
        
    except Exception as e:
        print(f"‚ùå Example failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 